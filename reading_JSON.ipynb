{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/26 16:27:50 WARN Utils: Your hostname, abdul-basit-HP-ProBook-450-G8-Notebook-PC resolves to a loopback address: 127.0.1.1; using 10.11.16.155 instead (on interface wlp0s20f3)\n",
      "24/09/26 16:27:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/26 16:27:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "options() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minfer_schema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\\\n\u001b[1;32m      3\u001b[0m           \u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBasics/json_data.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: options() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"json\")\\\n",
    "          .options(\"infer_schema\", True)\\\n",
    "          .load(\"Basics/json_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath= 'iris.json'\n",
    "json_df=spark.read.json(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------+-----------+----------+-------+\n",
      "|_corrupt_record|petalLength|petalWidth|sepalLength|sepalWidth|species|\n",
      "+---------------+-----------+----------+-----------+----------+-------+\n",
      "|              [|       NULL|      NULL|       NULL|      NULL|   NULL|\n",
      "|           NULL|        1.4|       0.2|        5.1|       3.5| setosa|\n",
      "|           NULL|        1.4|       0.2|        4.9|       3.0| setosa|\n",
      "|           NULL|        1.3|       0.2|        4.7|       3.2| setosa|\n",
      "|           NULL|        1.5|       0.2|        4.6|       3.1| setosa|\n",
      "|           NULL|        1.4|       0.2|        5.0|       3.6| setosa|\n",
      "|           NULL|        1.7|       0.4|        5.4|       3.9| setosa|\n",
      "|           NULL|        1.4|       0.3|        4.6|       3.4| setosa|\n",
      "|           NULL|        1.5|       0.2|        5.0|       3.4| setosa|\n",
      "|           NULL|        1.4|       0.2|        4.4|       2.9| setosa|\n",
      "|           NULL|        1.5|       0.1|        4.9|       3.1| setosa|\n",
      "|           NULL|        1.5|       0.2|        5.4|       3.7| setosa|\n",
      "|           NULL|        1.6|       0.2|        4.8|       3.4| setosa|\n",
      "|           NULL|        1.4|       0.1|        4.8|       3.0| setosa|\n",
      "|           NULL|        1.1|       0.1|        4.3|       3.0| setosa|\n",
      "|           NULL|        1.2|       0.2|        5.8|       4.0| setosa|\n",
      "|           NULL|        1.5|       0.4|        5.7|       4.4| setosa|\n",
      "|           NULL|        1.3|       0.4|        5.4|       3.9| setosa|\n",
      "|           NULL|        1.4|       0.3|        5.1|       3.5| setosa|\n",
      "|           NULL|        1.7|       0.3|        5.7|       3.8| setosa|\n",
      "+---------------+-----------+----------+-----------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Droping the column _corrupted_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-------+\n",
      "|petalLength|petalWidth|sepalLength|sepalWidth|species|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "|       NULL|      NULL|       NULL|      NULL|   NULL|\n",
      "|        1.4|       0.2|        5.1|       3.5| setosa|\n",
      "|        1.4|       0.2|        4.9|       3.0| setosa|\n",
      "|        1.3|       0.2|        4.7|       3.2| setosa|\n",
      "|        1.5|       0.2|        4.6|       3.1| setosa|\n",
      "|        1.4|       0.2|        5.0|       3.6| setosa|\n",
      "|        1.7|       0.4|        5.4|       3.9| setosa|\n",
      "|        1.4|       0.3|        4.6|       3.4| setosa|\n",
      "|        1.5|       0.2|        5.0|       3.4| setosa|\n",
      "|        1.4|       0.2|        4.4|       2.9| setosa|\n",
      "|        1.5|       0.1|        4.9|       3.1| setosa|\n",
      "|        1.5|       0.2|        5.4|       3.7| setosa|\n",
      "|        1.6|       0.2|        4.8|       3.4| setosa|\n",
      "|        1.4|       0.1|        4.8|       3.0| setosa|\n",
      "|        1.1|       0.1|        4.3|       3.0| setosa|\n",
      "|        1.2|       0.2|        5.8|       4.0| setosa|\n",
      "|        1.5|       0.4|        5.7|       4.4| setosa|\n",
      "|        1.3|       0.4|        5.4|       3.9| setosa|\n",
      "|        1.4|       0.3|        5.1|       3.5| setosa|\n",
      "|        1.7|       0.3|        5.7|       3.8| setosa|\n",
      "+-----------+----------+-----------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_df = json_df.drop(\"_corrupt_record\")\n",
    "json_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+----------+\n",
      "|petalLength|petalWidth|sepalLength|sepalWidth|   species|\n",
      "+-----------+----------+-----------+----------+----------+\n",
      "|        4.5|       1.5|        5.4|       3.0|versicolor|\n",
      "|        5.5|       2.1|        6.8|       3.0| virginica|\n",
      "|        1.2|       0.2|        5.0|       3.2|    setosa|\n",
      "|        5.1|       2.0|        6.5|       3.2| virginica|\n",
      "|        1.9|       0.4|        5.1|       3.8|    setosa|\n",
      "|        1.6|       0.6|        5.0|       3.5|    setosa|\n",
      "|        5.3|       2.3|        6.4|       3.2| virginica|\n",
      "|        5.1|       1.9|        5.8|       2.7| virginica|\n",
      "|        1.3|       0.4|        5.4|       3.9|    setosa|\n",
      "|        4.5|       1.3|        5.7|       2.8|versicolor|\n",
      "|        5.8|       1.6|        7.2|       3.0| virginica|\n",
      "|        3.3|       1.0|        4.9|       2.4|versicolor|\n",
      "|        4.3|       1.3|        6.4|       2.9|versicolor|\n",
      "|        5.7|       2.3|        6.9|       3.2| virginica|\n",
      "|        4.7|       1.5|        6.7|       3.1|versicolor|\n",
      "|        4.4|       1.4|        6.7|       3.1|versicolor|\n",
      "|        1.5|       0.1|        4.9|       3.1|    setosa|\n",
      "|        1.5|       0.2|        5.1|       3.4|    setosa|\n",
      "|        4.2|       1.2|        5.7|       3.0|versicolor|\n",
      "|        5.2|       2.0|        6.5|       3.0| virginica|\n",
      "+-----------+----------+-----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_row = json_df.limit(1)\n",
    "json_df = json_df.subtract(first_row)\n",
    "\n",
    "json_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"json_data.json\", multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+------------+--------------+------+\n",
      "|age|     department|is_full_time|          name|salary|\n",
      "+---+---------------+------------+--------------+------+\n",
      "| 28|    Engineering|        true|     Ahmed Ali| 80000|\n",
      "| 32|Human Resources|        true|   Ayesha Khan| 75000|\n",
      "| 45|        Finance|        true|   Usman Tariq| 90000|\n",
      "| 29|    Engineering|       false| Fatima Shaikh| 85000|\n",
      "| 26|      Marketing|        true|Zainab Qureshi| 60000|\n",
      "| 38|          Sales|        true|      Ali Raza| 70000|\n",
      "| 41|          Legal|        true|   Mariam Shah| 95000|\n",
      "| 52|        Finance|       false| Tariq Mehmood|110000|\n",
      "| 30|    Engineering|        true|   Saima Akram| 82000|\n",
      "| 34|      Marketing|        true|  Imran Farooq| 67000|\n",
      "+---+---------------+------------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"json_data.json\", multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- is_full_time: boolean (nullable = true)\n",
      " |-- leave: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+---------------+------+------------+-----+\n",
      "|          name|age|     department|salary|is_full_time|leave|\n",
      "+--------------+---+---------------+------+------------+-----+\n",
      "|     Ahmed Ali| 28|    Engineering| 80000|        true| NULL|\n",
      "|   Ayesha Khan| 32|Human Resources| 75000|        true| NULL|\n",
      "|   Usman Tariq| 45|        Finance| 90000|        true| NULL|\n",
      "| Fatima Shaikh| 29|    Engineering| 85000|       false| NULL|\n",
      "|Zainab Qureshi| 26|      Marketing| 60000|        true| NULL|\n",
      "|      Ali Raza| 38|          Sales| 70000|        true| NULL|\n",
      "|   Mariam Shah| 41|          Legal| 95000|        true| NULL|\n",
      "| Tariq Mehmood| 52|        Finance|110000|       false| NULL|\n",
      "|   Saima Akram| 30|    Engineering| 82000|        true| NULL|\n",
      "|  Imran Farooq| 34|      Marketing| 67000|        true|    2|\n",
      "+--------------+---+---------------+------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(\"name\",\"age\",\"department\",\"salary\",\"is_full_time\",\"leave\")\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
